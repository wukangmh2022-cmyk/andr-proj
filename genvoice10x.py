import re
import asyncio
import edge_tts
import os
import subprocess
import shutil
from datetime import datetime
from typing import List, Tuple, Optional

class SrtTTSGenerator:
    def __init__(self, max_concurrent_tasks=16):
        self.temp_dir = os.path.join(os.getcwd(), 'temp')
        os.makedirs(self.temp_dir, exist_ok=True)
        self.semaphore = asyncio.Semaphore(max_concurrent_tasks)
        
        # [æ–°å¢] æ—¶é•¿åå·®é…ç½® (ç”¨äºä¸²è¡Œæ—¥å¿—)
        self.max_duration_deviation_ratio = 0.02  # 2%
        self.min_duration_deviation_sec = 0.050 # 50ms (ç»å¯¹é˜ˆå€¼)
        # [æ–°å¢] ç´¯è®¡åå·®é˜ˆå€¼
        self.max_cumulative_deviation_sec = 1.0 # å…è®¸çš„æœ€å¤§ç´¯è®¡åå·® (ç§’)

        print(f"ä¸´æ—¶æ–‡ä»¶ç›®å½•: {self.temp_dir}")
        print(f"æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°: {max_concurrent_tasks}")
        print(f"âœ“ ç­–ç•¥: [é«˜ç²¾åº¦ WAV æ¨¡å¼] - TTS è¾ƒçŸ­åˆ™å¡«å……é™éŸ³ï¼ŒTTS è¾ƒé•¿åˆ™åŠ é€Ÿå¤„ç†ã€‚")

    def read_text_file(self, file_path):
        """ä»æ–‡ä»¶è¯»å–æ–‡æœ¬å†…å®¹"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            print(f"âŒ é”™è¯¯: æ–‡ä»¶ {file_path} ä¸å­˜åœ¨")
            return None
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return None

    def time_to_seconds_srt(self, time_str):
        """å°† SRT æ—¶é—´å­—ç¬¦ä¸² (HH:MM:SS,mmm) è½¬æ¢ä¸ºç§’æ•°"""
        try:
            parts = time_str.split(':')
            h = int(parts[0])
            m = int(parts[1])
            sec_ms = parts[2].split(',')
            s = int(sec_ms[0])
            ms = int(sec_ms[1])
            total_sec = (h * 3600) + (m * 60) + s + (ms / 1000.0)
            return total_sec
        except Exception as e:
            print(f"âŒ é”™è¯¯çš„æ—¶é—´æ ¼å¼: {time_str} - {e}")
            return 0

    def parse_srt_file(self, srt_content):
        """è§£æ SRT æ–‡ä»¶å†…å®¹,è¿”å›: [(start_sec, end_sec, text), ...]"""
        segments = []
        pattern = re.compile(
            r'(\d+)\n'
            r'(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n'
            r'([\s\S]*?)(?=\n\n|\Z)',
            re.MULTILINE
        )
        for match in pattern.finditer(srt_content):
            try:
                start_time_str = match.group(2)
                end_time_str = match.group(3)
                text_block = match.group(4)
                start_sec = self.time_to_seconds_srt(start_time_str)
                end_sec = self.time_to_seconds_srt(end_time_str)
                text = re.sub(r'\s+', ' ', text_block).strip()
                if text:
                    segments.append((start_sec, end_sec, text))
            except Exception as e:
                print(f"âŒ è§£æSRTæ¡ç›®å¤±è´¥: {match.group(0)} - {e}")
        print(f"âœ“ SRT è§£æå®Œæˆï¼Œå…± {len(segments)} ä¸ªç‰‡æ®µ")
        return segments

    async def generate_tts_with_retry(self, text, output_file_wav, voice, rate, max_retries=3):
        """[ä¿®æ”¹] ç”Ÿæˆ TTS å¹¶ç«‹å³è½¬ä¸º WAV"""
        for attempt in range(max_retries):
            try:
                async with self.semaphore:
                    # Edge-TTS åªèƒ½ç”Ÿæˆ MP3
                    temp_mp3 = output_file_wav + ".temp_tts.mp3"
                    communicate = edge_tts.Communicate(text, voice, rate=rate)
                    await communicate.save(temp_mp3)
                    
                    if not os.path.exists(temp_mp3):
                        raise Exception("TTSç”ŸæˆMP3æ–‡ä»¶ä¸å­˜åœ¨")
                    
                    # [å…³é”®] ç«‹å³è½¬æ¢ä¸º WAV (PCM 16-bit)
                    subprocess.run([
                        'ffmpeg', '-i', temp_mp3,
                        '-ar', '44100', '-ac', '2', '-f', 'wav', '-c:a', 'pcm_s16le',
                        '-y', output_file_wav
                    ], capture_output=True, text=True, check=True)
                    
                    actual_duration = self.get_audio_duration(output_file_wav)
                    os.remove(temp_mp3)
                    return output_file_wav, actual_duration
            except Exception as e:
                if attempt < max_retries - 1:
                    await asyncio.sleep(1 * (attempt + 1))  # é€’å¢å»¶è¿Ÿ
                    continue
                print(f" âœ— TTSç”Ÿæˆå¤±è´¥ (é‡è¯•{max_retries}æ¬¡): {e}")
                for f in [temp_mp3, output_file_wav]:
                    if os.path.exists(f): 
                        os.remove(f)
                return None, 0

    async def create_silence(self, output_file_wav, duration):
        """[ä¿®æ”¹] ç”Ÿæˆé™éŸ³ (å¼‚æ­¥ WAV)"""
        try:
            await asyncio.to_thread(
                self.create_silence_sync, output_file_wav, duration
            )
            return output_file_wav if os.path.exists(output_file_wav) else None
        except Exception as e:
            print(f" âœ— ç”Ÿæˆé™éŸ³å¤±è´¥: {e}")
            return None

    def create_silence_sync(self, output_file_wav, duration):
        """[ä¿®æ”¹] ç”Ÿæˆé™éŸ³ (åŒæ­¥ WAV)"""
        try:
            if duration <= 0:
                return None
            subprocess.run([
                'ffmpeg',
                '-f', 'lavfi', '-t', str(duration), '-i', 'anullsrc=r=44100:cl=stereo',
                '-ar', '44100', '-ac', '2', '-f', 'wav', '-c:a', 'pcm_s16le',
                '-y', output_file_wav
            ], capture_output=True, text=True, check=True)
            return output_file_wav
        except Exception as e:
            print(f" âœ— [Sync] ç”Ÿæˆé™éŸ³WAVå¤±è´¥: {e}")
            return None


    def get_audio_duration(self, audio_file):
        """è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿ (WAV éå¸¸ç²¾ç¡®)"""
        try:
            if not os.path.exists(audio_file) or os.path.getsize(audio_file) == 0:
                return 0
            result = subprocess.run([
                'ffprobe', '-v', 'error',
                '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                audio_file
            ], capture_output=True, text=True)
            return float(result.stdout.strip())
        except:
            return 0

    def stretch_audio_to_duration(self, input_file_wav, output_file_wav, target_duration):
        """
        [ä¿®æ”¹] WAV é«˜ç²¾åº¦å¤„ç†
        - å¦‚æœ TTS æ—¶é•¿ < ç›®æ ‡æ—¶é•¿: ä¿æŒåŸé€Ÿï¼Œå°¾éƒ¨å¡«å……é™éŸ³ã€‚
        - å¦‚æœ TTS æ—¶é•¿ > ç›®æ ‡æ—¶é•¿: åŠ é€Ÿï¼ˆå‹ç¼©ï¼‰éŸ³é¢‘ä»¥åŒ¹é…ç›®æ ‡ã€‚
        """
        try:
            current_duration = self.get_audio_duration(input_file_wav)
            
            # Case 0: æ—¶é•¿å‡ ä¹ä¸€è‡´ (å®¹å¿ 5ms è¯¯å·®, WAVå¯ä»¥æ›´ç²¾ç¡®)
            if abs(current_duration - target_duration) < 0.005:
                shutil.copy(input_file_wav, output_file_wav)
                return True, "no_change"

            # Case 1: TTS æ—¶é•¿ < ç›®æ ‡æ—¶é•¿ (ä¿æŒåŸé€Ÿï¼Œå°¾éƒ¨å¡«å……é™éŸ³)
            if current_duration < target_duration:
                padding_duration = target_duration - current_duration
                
                silence_file = output_file_wav + ".temp_silence.wav"
                if not self.create_silence_sync(silence_file, padding_duration):
                    raise Exception("Failed to create silence for padding")

                # æ‹¼æ¥ [input_file] + [silence_file] -> [output_file]
                list_file = output_file_wav + '.concat_list.txt'
                with open(list_file, 'w', encoding='utf-8') as f:
                    f.write(f"file '{os.path.abspath(input_file_wav)}'\n")
                    f.write(f"file '{os.path.abspath(silence_file)}'\n")
                
                # [å…³é”®] WAV ä½¿ç”¨ -c copy å¿«é€Ÿæ— æŸæ‹¼æ¥
                subprocess.run([
                    'ffmpeg', '-f', 'concat', '-safe', '0', '-i', list_file,
                    '-c', 'copy', # å¤åˆ¶ WAV æ•°æ®æµï¼Œæå¿«ä¸”æ— æŸ
                    '-y', output_file_wav
                ], capture_output=True, text=True, check=True)
                
                os.remove(silence_file)
                os.remove(list_file)
                return True, "åŸé€Ÿ+é™éŸ³å¡«å……"

            # Case 2: TTS æ—¶é•¿ > ç›®æ ‡æ—¶é•¿ (åŠ é€ŸéŸ³é¢‘)
            else: # current_duration > target_duration
                atempo_factor = current_duration / target_duration # å› å­ > 1.0

                filter_chain = []
                while atempo_factor > 2.0:
                    filter_chain.append("atempo=2.0")
                    atempo_factor /= 2.0
                
                safe_factor = max(0.5, min(2.0, atempo_factor))
                filter_chain.append(f"atempo={safe_factor:.3f}")

                filter_string = ",".join(filter_chain)
                
                temp_stretched = output_file_wav + ".temp_stretched.wav"
                subprocess.run([
                    'ffmpeg', '-i', input_file_wav,
                    '-filter:a', filter_string,
                    '-f', 'wav', '-c:a', 'pcm_s16le',
                    '-y', temp_stretched
                ], capture_output=True, text=True, check=True)
                
                # [å…³é”®] ä¿®æ­£ atempo çš„å¾®å°è¯¯å·® (æˆªæ–­æˆ–è¡¥é½)
                stretched_duration = self.get_audio_duration(temp_stretched)
                residual = target_duration - stretched_duration
                
                if abs(residual) < 0.005: # 5ms å†…ï¼Œå¯æ¥å—
                    shutil.move(temp_stretched, output_file_wav)
                elif residual > 0: # åŠ é€Ÿåæ–‡ä»¶ç•¥çŸ­ï¼Œè¡¥é™éŸ³
                    self.stretch_audio_to_duration(temp_stretched, output_file_wav, target_duration)
                    os.remove(temp_stretched)
                elif residual < 0: # åŠ é€Ÿåæ–‡ä»¶ç•¥é•¿ï¼Œæˆªæ–­
                    subprocess.run([
                        'ffmpeg', '-i', temp_stretched,
                        '-t', str(target_duration), # æˆªæ–­åˆ°ç›®æ ‡æ—¶é•¿
                        '-c', 'copy',
                        '-y', output_file_wav
                    ], capture_output=True, text=True, check=True)
                    os.remove(temp_stretched)

                return True, "åŠ é€Ÿ"

        except Exception as e:
            print(f" âœ— éŸ³é¢‘å¤„ç† (åŠ é€Ÿ/å¡«å……) å¤±è´¥: {e}")
            shutil.copy(input_file_wav, output_file_wav)
            return False, "error"

    def concatenate_audio_files(self, audio_files, output_wav):
        """[ä¿®æ”¹] æ‹¼æ¥ WAV æ–‡ä»¶ (ä½¿ç”¨ -c copy)"""
        valid_files = [f for f in audio_files if os.path.exists(f) and os.path.getsize(f) > 0]
        if not valid_files:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„ WAV æ–‡ä»¶")
            return False
        
        print(f"\næ‹¼æ¥ {len(valid_files)} ä¸ª WAV ç‰‡æ®µ...")
        list_file = os.path.join(self.temp_dir, 'concat_list.txt')
        
        with open(list_file, 'w', encoding='utf-8') as f:
            for audio_file in valid_files:
                abs_path = os.path.abspath(audio_file)
                f.write(f"file '{abs_path}'\n")
        
        try:
            subprocess.run([
                'ffmpeg',
                '-f', 'concat', '-safe', '0', '-i', list_file,
                '-c', 'copy', # WAV å¿…é¡»ç”¨ copy
                '-y', output_wav
            ], capture_output=True, text=True, check=True)
            
            if os.path.exists(list_file): 
                os.remove(list_file)
            
            if os.path.exists(output_wav) and os.path.getsize(output_wav) > 0:
                final_duration = self.get_audio_duration(output_wav)
                print(f"âœ“ WAV æ‹¼æ¥æˆåŠŸ (æ€»æ—¶é•¿: {final_duration:.1f}ç§’)")
                return True
            else:
                print("âŒ æ‹¼æ¥å WAV æ–‡ä»¶æ— æ•ˆ")
                return False
        except Exception as e:
            print(f"âŒ WAV æ‹¼æ¥å¤±è´¥: {e}")
            if os.path.exists(list_file): 
                os.remove(list_file)
            return False

    def convert_wav_to_mp3(self, wav_file, mp3_file):
        """[æ–°å¢] æœ€ç»ˆå°† WAV è½¬æ¢ä¸º MP3"""
        print(f"\næ­£åœ¨å°† {wav_file} è½¬æ¢ä¸º {mp3_file}...")
        try:
            subprocess.run([
                'ffmpeg', '-i', wav_file,
                '-c:a', 'libmp3lame', '-b:a', '192k',
                '-y', mp3_file
            ], capture_output=True, text=True, check=True)
            
            if os.path.exists(mp3_file):
                print("âœ“ MP3 è½¬æ¢æˆåŠŸ")
                return True
            return False
        except Exception as e:
            print(f"âŒ WAV è½¬ MP3 å¤±è´¥: {e}")
            return False


    async def process_single_segment(self, i, start_sec, end_sec, text, voice, rate, current_time_sec):
        """[ä¿®æ”¹] å¤„ç†å•ä¸ªç‰‡æ®µ, è¾“å‡º WAV, å¹¶è¿”å›æ–‡ä»¶åˆ—è¡¨"""
        
        segment_files_tuples = [] # å­˜å‚¨ ('gap'/'audio', file_path)
        
        # 1. ç”Ÿæˆé™éŸ³é—´éš™
        gap_duration_target = start_sec - current_time_sec
        
        if gap_duration_target > 0.05:
            silence_file = os.path.join(self.temp_dir, f"seg_{i:04d}_gap.wav") # .wav
            res = await self.create_silence(silence_file, gap_duration_target)
            if res:
                segment_files_tuples.append(('gap', silence_file))
            else:
                print(f"âœ— è­¦å‘Š: ç‰‡æ®µ {i:04d} é™éŸ³ç”Ÿæˆå¤±è´¥ã€‚")
        
        # 2. ç”ŸæˆTTSéŸ³é¢‘
        target_tts_duration = end_sec - start_sec
        if target_tts_duration <= 0.01:
             # è¿™æ˜¯ä¸€ä¸ªçº¯é™éŸ³ç‰‡æ®µ
            return segment_files_tuples, True

        tts_raw_file = os.path.join(self.temp_dir, f"seg_{i:04d}_raw.wav") # .wav
        tts_final_file = os.path.join(self.temp_dir, f"seg_{i:04d}_final.wav") # .wav
        
        result, actual_duration = await self.generate_tts_with_retry(text, tts_raw_file, voice, rate)
        if not result:
            return segment_files_tuples, False # TTS å½»åº•å¤±è´¥
        
        # 3. æ‹‰ä¼¸(åŠ é€Ÿ)/å¡«å……é™éŸ³
        success, action = await asyncio.to_thread(
            self.stretch_audio_to_duration,
            tts_raw_file, tts_final_file, target_tts_duration
        )
        
        if not success:
            print(f" âœ— ç‰‡æ®µ {i:04d} å¤„ç†å¤±è´¥ (Action: {action})ï¼Œä½¿ç”¨äº†å›é€€æ–‡ä»¶ã€‚")
            
        if os.path.exists(tts_raw_file):
            os.remove(tts_raw_file)
        
        segment_files_tuples.append(('audio', tts_final_file))
        return segment_files_tuples, True
    
    
    def validate_segment_durations(self, segments, results):
        """
        [æ–°å¢] ä¸²è¡Œæ—¶é•¿æ ¡éªŒ (åœ¨æ‹¼æ¥å‰è¿è¡Œ)
        è¯»å–æ‰€æœ‰ç”Ÿæˆçš„ WAV æ–‡ä»¶ï¼Œè®¡ç®—ç´¯è®¡åå·®
        """
        print(f"\n{'='*60}")
        print(f"ğŸ”¬ å¼€å§‹æ‰§è¡Œæ‹¼æ¥å‰ä¸²è¡Œæ—¶é•¿æ ¡éªŒ...")
        
        cumulative_deviation = 0.0
        last_srt_end_sec = 0.0
        
        for i, (start_sec, end_sec, text) in enumerate(segments):
            
            result = results[i]
            if isinstance(result, Exception):
                print(f"[{i:04d}] âœ— è·³è¿‡æ ¡éªŒ (ä»»åŠ¡æ‰§è¡Œå¤±è´¥)")
                continue

            segment_files, success = result
            if not success:
                print(f"[{i:04d}] âœ— è·³è¿‡æ ¡éªŒ (ç‰‡æ®µå¤„ç†å¤±è´¥)")
                continue

            actual_gap_duration = 0.0
            actual_tts_duration = 0.0
            
            # 1. ç›´æ¥è¯»å–æ–‡ä»¶è·å–å®é™…æ—¶é•¿
            for file_type, file_path in segment_files:
                duration = self.get_audio_duration(file_path)
                if file_type == 'gap':
                    actual_gap_duration = duration
                elif file_type == 'audio':
                    actual_tts_duration = duration

            actual_total_duration = actual_gap_duration + actual_tts_duration
            
            # 2. è®¡ç®—ç›®æ ‡æ—¶é•¿
            target_total_duration = end_sec - last_srt_end_sec
            target_gap_duration = start_sec - last_srt_end_sec
            target_tts_duration = end_sec - start_sec

            # 3. è®¡ç®—åå·®
            deviation = actual_total_duration - target_total_duration
            cumulative_deviation += deviation
            
            allowed_deviation_abs = max(
                target_total_duration * self.max_duration_deviation_ratio, 
                self.min_duration_deviation_sec
            )
            
            # 4. æ‰“å°è­¦å‘Š
            if abs(deviation) > allowed_deviation_abs:
                print(f"âš ï¸  [æ—¶é•¿è­¦å‘Š] ç‰‡æ®µ {i:04d}: ç›®æ ‡ {target_total_duration:.3f}s, å®é™… {actual_total_duration:.3f}s. "
                      f"åå·® {deviation:+.3f}s (ç´¯è®¡ {cumulative_deviation:+.3f}s)")
                # (å¯é€‰) è¯¦ç»†æ—¥å¿—
                # print(f"    ... ç›®æ ‡: (Gap: {target_gap_duration:.3f}s + TTS: {target_tts_duration:.3f}s)")
                # print(f"    ... å®é™…: (Gap: {actual_gap_duration:.3f}s + TTS: {actual_tts_duration:.3f}s) - {text[:30]}...")

            last_srt_end_sec = end_sec

        # æœ€ç»ˆæ€»ç»“
        print(f"\n--- æ ¡éªŒå®Œæ¯• ---")
        print(f"SRT ç›®æ ‡æ€»æ—¶é•¿: {last_srt_end_sec:.3f}s")
        print(f"WAV ç´¯è®¡æ€»æ—¶é•¿: {(last_srt_end_sec + cumulative_deviation):.3f}s")
        print(f"æœ€ç»ˆç´¯è®¡åå·®: {cumulative_deviation:+.3f}s")
        
        if abs(cumulative_deviation) > self.max_cumulative_deviation_sec:
            print(f"âŒ é”™è¯¯: ç´¯è®¡åå·® ({cumulative_deviation:.3f}s) è¶…è¿‡é˜ˆå€¼ ({self.max_cumulative_deviation_sec:.3f}s)ã€‚")
            print(f"âŒ ç»ˆæ­¢æ‹¼æ¥ä»¥é¿å…éŸ³ç”»ä¸åŒæ­¥ã€‚è¯·æ£€æŸ¥ä¸Šæ–¹ [æ—¶é•¿è­¦å‘Š] æ—¥å¿—ã€‚")
            return False
        
        print(f"âœ“ ç´¯è®¡åå·®åœ¨å…è®¸èŒƒå›´å†…ã€‚")
        return True


    async def generate_audio_from_file(self, input_file="1.srt", output_file="æˆ‘çš„éŸ³é¢‘.mp3", 
                                      voice='zh-CN-XiaoyiNeural', rate='+0%'):
        """[ä¿®æ”¹] å®Œæ•´æµç¨‹: WAV -> æ ¡éªŒ -> æ‹¼æ¥ -> MP3"""
        start_time = datetime.now()
        print(f"\n{'='*60}")
        print(f"å¼€å§‹å¤„ç† SRT: {input_file}")
        print(f"è¯­é€Ÿè®¾ç½®: {rate}")
        print(f"å¹¶å‘çº¿ç¨‹: {self.semaphore._value}")
        print(f"{'='*60}\n")
        
        srt_content = self.read_text_file(input_file)
        if srt_content is None: return None
        segments = self.parse_srt_file(srt_content)
        if not segments: return None
        
        total_segments = len(segments)
        print(f"\n=== (1/4) å¼€å§‹å¹¶å‘å¤„ç† {total_segments} ä¸ª WAV ç‰‡æ®µ ===\n")
        
        tasks = []
        current_time_sec = 0.0
        for i, (start_sec, end_sec, text) in enumerate(segments):
            task = self.process_single_segment(i, start_sec, end_sec, text, voice, rate, current_time_sec)
            tasks.append(task)
            current_time_sec = end_sec
        
        # 1. å¹¶å‘æ‰§è¡Œ
        print(f"ğŸš€ å¯åŠ¨ {len(tasks)} ä¸ªå¹¶å‘ä»»åŠ¡...")
        results = await asyncio.gather(*tasks, return_exceptions=True)
        print(f"\nâœ“ å¹¶å‘å¤„ç†å®Œæˆã€‚")
        
        # 2. [æ–°å¢] ä¸²è¡Œæ ¡éªŒ
        if not self.validate_segment_durations(segments, results):
            return None # æ ¡éªŒå¤±è´¥ï¼Œç»ˆæ­¢
        
        # 3. æ”¶é›†æ–‡ä»¶å¹¶æ‹¼æ¥
        print(f"\n=== (3/4) å¼€å§‹æ‹¼æ¥ WAV æ–‡ä»¶ ===\n")
        audio_files_to_concat = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                print(f"[{i+1}/{total_segments}] âœ— è·³è¿‡æ‹¼æ¥ (ä»»åŠ¡å¤±è´¥: {result})")
                continue
            
            segment_files, success = result
            if not success:
                print(f"[{i+1}/{total_segments}] âœ— è·³è¿‡æ‹¼æ¥ (ç‰‡æ®µå¤„ç†å¤±è´¥)")
                continue

            for file_type, file_path in segment_files:
                audio_files_to_concat.append(file_path)
        
        # æ‹¼æ¥ä¸ºæœ€ç»ˆ WAV
        final_wav = os.path.join(self.temp_dir, "final_output.wav")
        if not self.concatenate_audio_files(audio_files_to_concat, final_wav):
            print("âŒ WAV æ‹¼æ¥å¤±è´¥")
            return None
            
        # 4. è½¬æ¢
        print(f"\n=== (4/4) è½¬æ¢ä¸º MP3 ===\n")
        if self.convert_wav_to_mp3(final_wav, output_file):
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()
            
            if os.path.exists(output_file):
                final_size = os.path.getsize(output_file) / 1024 / 1024
                final_duration = self.get_audio_duration(output_file)
                print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼")
                print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
                print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {final_size:.2f} MB")
                print(f"â±ï¸ éŸ³é¢‘æ—¶é•¿: {final_duration:.1f} ç§’ ({final_duration/60:.1f} åˆ†é’Ÿ)")
                print(f"â° å¤„ç†æ—¶é—´: {processing_time:.1f} ç§’")
                print(f"ğŸš€ å¹³å‡é€Ÿåº¦: {total_segments/processing_time:.1f} ç‰‡æ®µ/ç§’")
                print(f"ğŸ’¡ æç¤º: ä¸´æ—¶æ–‡ä»¶ (WAV) ä¿å­˜åœ¨ {self.temp_dir}")
                return output_file
        
        print("âŒ æœ€ç»ˆ MP3 è½¬æ¢å¤±è´¥")
        return None


async def main():
    generator = SrtTTSGenerator(max_concurrent_tasks=16)
    
    output_file = await generator.generate_audio_from_file(
        input_file="1_åŸæ–‡.srt",
        output_file="æˆ‘çš„éŸ³é¢‘_from_srt.mp3",
        voice='zh-CN-XiaoyiNeural',
        rate='+0%'
    )
    
    if output_file:
        print("\nğŸ‰ å¤„ç†å®Œæˆï¼")
    else:
        print("\nğŸ’” å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")


if __name__ == "__main__":
    if os.name == 'nt':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    asyncio.run(main())